{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1771b629",
   "metadata": {},
   "source": [
    "# 와인 리뷰데이터 인덱싱\n",
    "- 벡터 DB : pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13b2f66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv(override=True, dotenv_path=\"../.env\")\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
    "OPENAI_EMBEDDING_MODEL = os.getenv(\"OPENAI_EMBEDDING_MODEL\")\n",
    "PINECONE_INDEX_NAME = os.getenv(\"PINECONE_INDEX_NAME\")\n",
    "PINECONE_NAMESPACE = os.getenv(\"PINECONE_NAMESPACE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2413ed3b",
   "metadata": {},
   "source": [
    "## document loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ffe0208d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 page_content=': 0\n",
      "country: Italy\n",
      "description: Aromas include tropical fruit, broom, brimstone and dried herb. The palate isn't overly expressive, offering unripened apple, citrus and dried sage alongside brisk acidity.\n",
      "designation: Vulkà Bianco\n",
      "points: 87\n",
      "price: \n",
      "province: Sicily & Sardinia\n",
      "region_1: Etna\n",
      "region_2: \n",
      "taster_name: Kerin O’Keefe\n",
      "taster_twitter_handle: @kerinokeefe\n",
      "title: Nicosia 2013 Vulkà Bianco  (Etna)\n",
      "variety: White Blend\n",
      "winery: Nicosia' metadata={'source': './wine_reviews/winemag-data-130k-v2.csv', 'row': 0}\n",
      "1 page_content=': 1\n",
      "country: Portugal\n",
      "description: This is ripe and fruity, a wine that is smooth while still structured. Firm tannins are filled out with juicy red berry fruits and freshened with acidity. It's  already drinkable, although it will certainly be better from 2016.\n",
      "designation: Avidagos\n",
      "points: 87\n",
      "price: 15.0\n",
      "province: Douro\n",
      "region_1: \n",
      "region_2: \n",
      "taster_name: Roger Voss\n",
      "taster_twitter_handle: @vossroger\n",
      "title: Quinta dos Avidagos 2011 Avidagos Red (Douro)\n",
      "variety: Portuguese Red\n",
      "winery: Quinta dos Avidagos' metadata={'source': './wine_reviews/winemag-data-130k-v2.csv', 'row': 1}\n",
      "2 page_content=': 2\n",
      "country: US\n",
      "description: Tart and snappy, the flavors of lime flesh and rind dominate. Some green pineapple pokes through, with crisp acidity underscoring the flavors. The wine was all stainless-steel fermented.\n",
      "designation: \n",
      "points: 87\n",
      "price: 14.0\n",
      "province: Oregon\n",
      "region_1: Willamette Valley\n",
      "region_2: Willamette Valley\n",
      "taster_name: Paul Gregutt\n",
      "taster_twitter_handle: @paulgwine\n",
      "title: Rainstorm 2013 Pinot Gris (Willamette Valley)\n",
      "variety: Pinot Gris\n",
      "winery: Rainstorm' metadata={'source': './wine_reviews/winemag-data-130k-v2.csv', 'row': 2}\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import CSVLoader\n",
    "\n",
    "loader = CSVLoader('./wine_reviews/winemag-data-130k-v2.csv')\n",
    "docs = loader.load()\n",
    "for i, d in enumerate(docs[:3]):\n",
    "    print(i, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4e24b02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "129971"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5e4b5f",
   "metadata": {},
   "source": [
    "## embedding 모델 객체 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7247453",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding 모델 객체 생성\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=OPENAI_EMBEDDING_MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac4f4be",
   "metadata": {},
   "source": [
    "## Pinecone객체, index객체 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c27dd9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone, ServerlessSpec\n",
    "\n",
    "\n",
    "# Pinecone 클라이언트를 초기화(객체생성)\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8dcd606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index 'wine-reviews' created successfully.\n"
     ]
    }
   ],
   "source": [
    "# pinecone에 index list 가져오기\n",
    "existing_indexes = pc.list_indexes()\n",
    "\n",
    "# 이름만 추출\n",
    "index_names = [index['name'] for index in existing_indexes.indexes]\n",
    "# print(index_names)\n",
    "\n",
    "\n",
    "if PINECONE_INDEX_NAME not in index_names:\n",
    "    pc.create_index(\n",
    "        name=PINECONE_INDEX_NAME,\n",
    "        dimension=1536,  # 모델 차원, openapi embeding model을 사용함. 정확하게 일치\n",
    "        metric=\"cosine\",  # 모델 메트릭, openapi embeding model 에서 사용하는 것 확인\n",
    "        spec=ServerlessSpec(\n",
    "            cloud=\"aws\",\n",
    "            region=\"us-east-1\"\n",
    "        )\n",
    "    )\n",
    "    print(f\"Index '{PINECONE_INDEX_NAME}' created successfully.\")\n",
    "else:\n",
    "    print(f\"Index '{PINECONE_INDEX_NAME}' already exists.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a76872",
   "metadata": {},
   "source": [
    "## Split 객체 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ebad8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split하기\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# 텍스트 분할기 설정 (예: 1000자씩 분할)\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000, \n",
    "    chunk_overlap=100,\n",
    "    # length_function=tiktoken_len,  # 토큰 기반 길이 측정    \n",
    "    length_function=len,  # 문자수   \n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    "    )\n",
    "\n",
    "# 문서를 분할\n",
    "chunks = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1198c8ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "129982"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0817897f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': './wine_reviews/winemag-data-130k-v2.csv', 'row': 2}, page_content=': 2\\ncountry: US\\ndescription: Tart and snappy, the flavors of lime flesh and rind dominate. Some green pineapple pokes through, with crisp acidity underscoring the flavors. The wine was all stainless-steel fermented.\\ndesignation: \\npoints: 87\\nprice: 14.0\\nprovince: Oregon\\nregion_1: Willamette Valley\\nregion_2: Willamette Valley\\ntaster_name: Paul Gregutt\\ntaster_twitter_handle: @paulgwine\\ntitle: Rainstorm 2013 Pinot Gris (Willamette Valley)\\nvariety: Pinot Gris\\nwinery: Rainstorm')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885a827c",
   "metadata": {},
   "source": [
    "## 배치 크기 단위로 저장하기\n",
    "- langchain_pinecone의 PineconeVectorStore으로 벡터 DB에 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "57c2ef46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 1 완료: 500개 문서 업로드\n",
      "배치 2 완료: 500개 문서 업로드\n",
      "배치 3 완료: 500개 문서 업로드\n",
      "배치 4 완료: 500개 문서 업로드\n",
      "배치 5 완료: 500개 문서 업로드\n",
      "배치 6 완료: 500개 문서 업로드\n",
      "배치 7 완료: 500개 문서 업로드\n",
      "배치 8 완료: 500개 문서 업로드\n",
      "배치 9 완료: 500개 문서 업로드\n",
      "배치 10 완료: 500개 문서 업로드\n",
      "배치 11 완료: 500개 문서 업로드\n",
      "배치 12 완료: 500개 문서 업로드\n",
      "배치 13 완료: 500개 문서 업로드\n",
      "배치 14 완료: 500개 문서 업로드\n",
      "배치 15 완료: 500개 문서 업로드\n",
      "배치 16 완료: 500개 문서 업로드\n",
      "배치 17 완료: 500개 문서 업로드\n",
      "배치 18 완료: 500개 문서 업로드\n",
      "배치 19 완료: 500개 문서 업로드\n",
      "배치 20 완료: 500개 문서 업로드\n",
      "배치 21 완료: 500개 문서 업로드\n",
      "배치 22 완료: 500개 문서 업로드\n",
      "배치 23 완료: 500개 문서 업로드\n",
      "배치 24 완료: 500개 문서 업로드\n",
      "배치 25 완료: 500개 문서 업로드\n",
      "배치 26 완료: 500개 문서 업로드\n",
      "배치 27 완료: 500개 문서 업로드\n",
      "배치 28 완료: 500개 문서 업로드\n",
      "배치 29 완료: 500개 문서 업로드\n",
      "배치 30 완료: 500개 문서 업로드\n",
      "배치 31 완료: 500개 문서 업로드\n",
      "배치 32 완료: 500개 문서 업로드\n",
      "배치 33 완료: 500개 문서 업로드\n",
      "배치 34 완료: 500개 문서 업로드\n",
      "배치 35 완료: 500개 문서 업로드\n",
      "배치 36 완료: 500개 문서 업로드\n",
      "배치 37 완료: 500개 문서 업로드\n",
      "배치 38 완료: 500개 문서 업로드\n",
      "배치 39 완료: 500개 문서 업로드\n",
      "배치 40 완료: 500개 문서 업로드\n",
      "배치 41 완료: 500개 문서 업로드\n",
      "배치 42 완료: 500개 문서 업로드\n",
      "배치 43 완료: 500개 문서 업로드\n",
      "배치 44 완료: 500개 문서 업로드\n",
      "배치 45 완료: 500개 문서 업로드\n",
      "배치 46 완료: 500개 문서 업로드\n",
      "배치 47 완료: 500개 문서 업로드\n",
      "배치 48 완료: 500개 문서 업로드\n",
      "배치 49 완료: 500개 문서 업로드\n",
      "배치 50 완료: 500개 문서 업로드\n",
      "배치 51 완료: 500개 문서 업로드\n",
      "배치 52 완료: 500개 문서 업로드\n",
      "배치 53 완료: 500개 문서 업로드\n",
      "배치 54 완료: 500개 문서 업로드\n",
      "배치 55 완료: 500개 문서 업로드\n",
      "배치 56 완료: 500개 문서 업로드\n",
      "배치 57 완료: 500개 문서 업로드\n",
      "배치 58 완료: 500개 문서 업로드\n",
      "배치 59 완료: 500개 문서 업로드\n",
      "배치 60 완료: 500개 문서 업로드\n",
      "배치 61 완료: 500개 문서 업로드\n",
      "배치 62 완료: 500개 문서 업로드\n",
      "배치 63 완료: 500개 문서 업로드\n",
      "배치 64 완료: 500개 문서 업로드\n",
      "배치 65 완료: 500개 문서 업로드\n",
      "배치 66 완료: 500개 문서 업로드\n",
      "배치 67 완료: 500개 문서 업로드\n",
      "배치 68 완료: 500개 문서 업로드\n",
      "배치 69 완료: 500개 문서 업로드\n",
      "배치 70 완료: 500개 문서 업로드\n",
      "배치 71 완료: 500개 문서 업로드\n",
      "배치 72 완료: 500개 문서 업로드\n",
      "배치 73 완료: 500개 문서 업로드\n",
      "배치 74 완료: 500개 문서 업로드\n",
      "배치 75 완료: 500개 문서 업로드\n",
      "배치 76 완료: 500개 문서 업로드\n",
      "배치 77 완료: 500개 문서 업로드\n",
      "배치 78 완료: 500개 문서 업로드\n",
      "배치 79 완료: 500개 문서 업로드\n",
      "배치 80 완료: 500개 문서 업로드\n",
      "배치 81 완료: 500개 문서 업로드\n",
      "배치 82 완료: 500개 문서 업로드\n",
      "배치 83 완료: 500개 문서 업로드\n",
      "배치 84 완료: 500개 문서 업로드\n",
      "배치 85 완료: 500개 문서 업로드\n",
      "배치 86 완료: 500개 문서 업로드\n",
      "배치 87 완료: 500개 문서 업로드\n",
      "배치 88 완료: 500개 문서 업로드\n",
      "배치 89 완료: 500개 문서 업로드\n",
      "배치 90 완료: 500개 문서 업로드\n",
      "배치 91 완료: 500개 문서 업로드\n",
      "배치 92 완료: 500개 문서 업로드\n",
      "배치 93 완료: 500개 문서 업로드\n",
      "배치 94 완료: 500개 문서 업로드\n",
      "배치 95 완료: 500개 문서 업로드\n",
      "배치 96 완료: 500개 문서 업로드\n",
      "배치 97 완료: 500개 문서 업로드\n",
      "배치 98 완료: 500개 문서 업로드\n",
      "배치 99 완료: 500개 문서 업로드\n",
      "배치 100 완료: 500개 문서 업로드\n",
      "배치 101 완료: 500개 문서 업로드\n",
      "배치 102 완료: 500개 문서 업로드\n",
      "배치 103 완료: 500개 문서 업로드\n",
      "배치 104 완료: 500개 문서 업로드\n",
      "배치 105 완료: 500개 문서 업로드\n",
      "배치 106 완료: 500개 문서 업로드\n",
      "배치 107 완료: 500개 문서 업로드\n",
      "배치 108 완료: 500개 문서 업로드\n",
      "배치 109 완료: 500개 문서 업로드\n",
      "배치 110 완료: 500개 문서 업로드\n",
      "배치 111 완료: 500개 문서 업로드\n",
      "배치 112 완료: 500개 문서 업로드\n",
      "배치 113 완료: 500개 문서 업로드\n",
      "배치 114 완료: 500개 문서 업로드\n",
      "배치 115 완료: 500개 문서 업로드\n",
      "배치 116 완료: 500개 문서 업로드\n",
      "배치 117 완료: 500개 문서 업로드\n",
      "배치 118 완료: 500개 문서 업로드\n",
      "배치 119 완료: 500개 문서 업로드\n",
      "배치 120 완료: 500개 문서 업로드\n",
      "배치 121 완료: 500개 문서 업로드\n",
      "배치 122 완료: 500개 문서 업로드\n",
      "배치 123 완료: 500개 문서 업로드\n",
      "배치 124 완료: 500개 문서 업로드\n",
      "배치 125 완료: 500개 문서 업로드\n",
      "배치 126 완료: 500개 문서 업로드\n",
      "배치 127 완료: 500개 문서 업로드\n",
      "배치 128 완료: 500개 문서 업로드\n",
      "배치 129 완료: 500개 문서 업로드\n",
      "배치 130 완료: 500개 문서 업로드\n",
      "배치 131 완료: 500개 문서 업로드\n",
      "배치 132 완료: 500개 문서 업로드\n",
      "배치 133 완료: 500개 문서 업로드\n",
      "배치 134 완료: 500개 문서 업로드\n",
      "배치 135 완료: 500개 문서 업로드\n",
      "배치 136 완료: 500개 문서 업로드\n",
      "배치 137 완료: 500개 문서 업로드\n",
      "배치 138 완료: 500개 문서 업로드\n",
      "배치 139 완료: 500개 문서 업로드\n",
      "배치 140 완료: 500개 문서 업로드\n",
      "배치 141 완료: 500개 문서 업로드\n",
      "배치 142 완료: 500개 문서 업로드\n",
      "배치 143 완료: 500개 문서 업로드\n",
      "배치 144 완료: 500개 문서 업로드\n",
      "배치 145 완료: 500개 문서 업로드\n",
      "배치 146 완료: 500개 문서 업로드\n",
      "배치 147 완료: 500개 문서 업로드\n",
      "배치 148 완료: 500개 문서 업로드\n",
      "배치 149 완료: 500개 문서 업로드\n",
      "배치 150 완료: 500개 문서 업로드\n",
      "배치 151 완료: 500개 문서 업로드\n",
      "배치 152 완료: 500개 문서 업로드\n",
      "배치 153 완료: 500개 문서 업로드\n",
      "배치 154 완료: 500개 문서 업로드\n",
      "배치 155 완료: 500개 문서 업로드\n",
      "배치 156 완료: 500개 문서 업로드\n",
      "배치 157 완료: 500개 문서 업로드\n",
      "배치 158 완료: 500개 문서 업로드\n",
      "배치 159 완료: 500개 문서 업로드\n",
      "배치 160 완료: 500개 문서 업로드\n",
      "배치 161 완료: 500개 문서 업로드\n",
      "배치 162 완료: 500개 문서 업로드\n",
      "배치 163 완료: 500개 문서 업로드\n",
      "배치 164 완료: 500개 문서 업로드\n",
      "배치 165 완료: 500개 문서 업로드\n",
      "배치 166 완료: 500개 문서 업로드\n",
      "배치 167 완료: 500개 문서 업로드\n",
      "배치 168 완료: 500개 문서 업로드\n",
      "배치 169 완료: 500개 문서 업로드\n",
      "배치 170 완료: 500개 문서 업로드\n",
      "배치 171 완료: 500개 문서 업로드\n",
      "배치 172 완료: 500개 문서 업로드\n",
      "배치 173 완료: 500개 문서 업로드\n",
      "배치 174 완료: 500개 문서 업로드\n",
      "배치 175 완료: 500개 문서 업로드\n",
      "배치 176 완료: 500개 문서 업로드\n",
      "배치 177 완료: 500개 문서 업로드\n",
      "배치 178 완료: 500개 문서 업로드\n",
      "배치 179 완료: 500개 문서 업로드\n",
      "배치 180 완료: 500개 문서 업로드\n",
      "배치 181 완료: 500개 문서 업로드\n",
      "배치 182 완료: 500개 문서 업로드\n",
      "배치 183 완료: 500개 문서 업로드\n",
      "배치 184 완료: 500개 문서 업로드\n",
      "배치 185 완료: 500개 문서 업로드\n",
      "배치 186 완료: 500개 문서 업로드\n",
      "배치 187 완료: 500개 문서 업로드\n",
      "배치 188 완료: 500개 문서 업로드\n",
      "배치 189 완료: 500개 문서 업로드\n",
      "배치 190 완료: 500개 문서 업로드\n",
      "배치 191 완료: 500개 문서 업로드\n",
      "배치 192 완료: 500개 문서 업로드\n",
      "배치 193 완료: 500개 문서 업로드\n",
      "배치 194 완료: 500개 문서 업로드\n",
      "배치 195 완료: 500개 문서 업로드\n",
      "배치 196 완료: 500개 문서 업로드\n",
      "배치 197 완료: 500개 문서 업로드\n",
      "배치 198 완료: 500개 문서 업로드\n",
      "배치 199 완료: 500개 문서 업로드\n",
      "배치 200 완료: 500개 문서 업로드\n",
      "배치 201 완료: 500개 문서 업로드\n",
      "배치 202 완료: 500개 문서 업로드\n",
      "배치 203 완료: 500개 문서 업로드\n",
      "배치 204 완료: 500개 문서 업로드\n",
      "배치 205 완료: 500개 문서 업로드\n",
      "배치 206 완료: 500개 문서 업로드\n",
      "배치 207 완료: 500개 문서 업로드\n",
      "배치 208 완료: 500개 문서 업로드\n",
      "배치 209 완료: 500개 문서 업로드\n",
      "배치 210 완료: 500개 문서 업로드\n",
      "배치 211 완료: 500개 문서 업로드\n",
      "배치 212 완료: 500개 문서 업로드\n",
      "배치 213 완료: 500개 문서 업로드\n",
      "배치 214 완료: 500개 문서 업로드\n",
      "배치 215 완료: 500개 문서 업로드\n",
      "배치 216 완료: 500개 문서 업로드\n",
      "배치 217 완료: 500개 문서 업로드\n",
      "배치 218 완료: 500개 문서 업로드\n",
      "배치 219 완료: 500개 문서 업로드\n",
      "배치 220 완료: 500개 문서 업로드\n",
      "배치 221 완료: 500개 문서 업로드\n",
      "배치 222 완료: 500개 문서 업로드\n"
     ]
    },
    {
     "ename": "RateLimitError",
     "evalue": "Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRateLimitError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[32m     11\u001b[39m     vector_store = PineconeVectorStore.from_documents(\n\u001b[32m     12\u001b[39m         batch_docs,            \u001b[38;5;66;03m# BATCH_SIZE 수 만큼의 chunk\u001b[39;00m\n\u001b[32m     13\u001b[39m         embedding=embeddings,  \u001b[38;5;66;03m# 임베딩 벡터로 변환\u001b[39;00m\n\u001b[32m     14\u001b[39m         index_name=PINECONE_INDEX_NAME,   \u001b[38;5;66;03m# index 이름\u001b[39;00m\n\u001b[32m     15\u001b[39m         namespace=PINECONE_NAMESPACE      \n\u001b[32m     16\u001b[39m     )\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# 이후 배치는 생성한 벡터 스토어에 추가, # 내부적으로 임베딩 벡터로 변환\u001b[39;00m\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m     \u001b[43mvector_store\u001b[49m\u001b[43m.\u001b[49m\u001b[43madd_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_docs\u001b[49m\u001b[43m)\u001b[49m    \n\u001b[32m     22\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m배치 \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi//BATCH_SIZE\u001b[38;5;250m \u001b[39m+\u001b[38;5;250m \u001b[39m\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m 완료: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(batch_docs)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m개 문서 업로드\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Admin\\miniconda3\\envs\\lc_env\\Lib\\site-packages\\langchain_core\\vectorstores\\base.py:257\u001b[39m, in \u001b[36mVectorStore.add_documents\u001b[39m\u001b[34m(self, documents, **kwargs)\u001b[39m\n\u001b[32m    255\u001b[39m     texts = [doc.page_content \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[32m    256\u001b[39m     metadatas = [doc.metadata \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[32m--> \u001b[39m\u001b[32m257\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43madd_texts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    258\u001b[39m msg = (\n\u001b[32m    259\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m`add_documents` and `add_texts` has not been implemented \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    260\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mfor \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    261\u001b[39m )\n\u001b[32m    262\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(msg)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Admin\\miniconda3\\envs\\lc_env\\Lib\\site-packages\\langchain_pinecone\\vectorstores.py:357\u001b[39m, in \u001b[36mPineconeVectorStore.add_texts\u001b[39m\u001b[34m(self, texts, metadatas, ids, namespace, batch_size, embedding_chunk_size, async_req, id_prefix, **kwargs)\u001b[39m\n\u001b[32m    355\u001b[39m chunk_ids = ids[i : i + embedding_chunk_size]\n\u001b[32m    356\u001b[39m chunk_metadatas = metadatas[i : i + embedding_chunk_size]\n\u001b[32m--> \u001b[39m\u001b[32m357\u001b[39m embeddings = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_embedding\u001b[49m\u001b[43m.\u001b[49m\u001b[43membed_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk_texts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    358\u001b[39m vector_tuples = \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(chunk_ids, embeddings, chunk_metadatas))\n\u001b[32m    359\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m async_req:\n\u001b[32m    360\u001b[39m     \u001b[38;5;66;03m# Runs the pinecone upsert asynchronously.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Admin\\miniconda3\\envs\\lc_env\\Lib\\site-packages\\langchain_openai\\embeddings\\base.py:709\u001b[39m, in \u001b[36mOpenAIEmbeddings.embed_documents\u001b[39m\u001b[34m(self, texts, chunk_size, **kwargs)\u001b[39m\n\u001b[32m    706\u001b[39m \u001b[38;5;66;03m# Unconditionally call _get_len_safe_embeddings to handle length safety.\u001b[39;00m\n\u001b[32m    707\u001b[39m \u001b[38;5;66;03m# This could be optimized to avoid double work when all texts are short enough.\u001b[39;00m\n\u001b[32m    708\u001b[39m engine = cast(\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mself\u001b[39m.deployment)\n\u001b[32m--> \u001b[39m\u001b[32m709\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_len_safe_embeddings\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    710\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m=\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    711\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Admin\\miniconda3\\envs\\lc_env\\Lib\\site-packages\\langchain_openai\\embeddings\\base.py:576\u001b[39m, in \u001b[36mOpenAIEmbeddings._get_len_safe_embeddings\u001b[39m\u001b[34m(self, texts, engine, chunk_size, **kwargs)\u001b[39m\n\u001b[32m    574\u001b[39m \u001b[38;5;66;03m# Make API call with this batch\u001b[39;00m\n\u001b[32m    575\u001b[39m batch_tokens = tokens[i:batch_end]\n\u001b[32m--> \u001b[39m\u001b[32m576\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m=\u001b[49m\u001b[43mbatch_tokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mclient_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    577\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, \u001b[38;5;28mdict\u001b[39m):\n\u001b[32m    578\u001b[39m     response = response.model_dump()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Admin\\miniconda3\\envs\\lc_env\\Lib\\site-packages\\openai\\resources\\embeddings.py:132\u001b[39m, in \u001b[36mEmbeddings.create\u001b[39m\u001b[34m(self, input, model, dimensions, encoding_format, user, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    126\u001b[39m             embedding.embedding = np.frombuffer(  \u001b[38;5;66;03m# type: ignore[no-untyped-call]\u001b[39;00m\n\u001b[32m    127\u001b[39m                 base64.b64decode(data), dtype=\u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    128\u001b[39m             ).tolist()\n\u001b[32m    130\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\n\u001b[32m--> \u001b[39m\u001b[32m132\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    133\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/embeddings\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    134\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mEmbeddingCreateParams\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    135\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    136\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    137\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    138\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    139\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    140\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpost_parser\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    142\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mCreateEmbeddingResponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    143\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Admin\\miniconda3\\envs\\lc_env\\Lib\\site-packages\\openai\\_base_client.py:1259\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1245\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1246\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1247\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1254\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1255\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1256\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1257\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1258\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1259\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Admin\\miniconda3\\envs\\lc_env\\Lib\\site-packages\\openai\\_base_client.py:1047\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1044\u001b[39m             err.response.read()\n\u001b[32m   1046\u001b[39m         log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1047\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1049\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1051\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mcould not resolve response (should never happen)\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mRateLimitError\u001b[39m: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}"
     ]
    }
   ],
   "source": [
    "# vector sotre에 저장(2시간정도 걸림)\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "BATCH_SIZE = 500  # 한 번에 처리할 문서 수(최대 vector 수 1000개, 2MB 이내)\n",
    "\n",
    "for i in range(0, len(chunks), BATCH_SIZE):\n",
    "    batch_docs = chunks[i:i+BATCH_SIZE]\n",
    "    \n",
    "    # 첫 번째 배치로 벡터 스토어 생성\n",
    "    if i == 0:\n",
    "        vector_store = PineconeVectorStore.from_documents(\n",
    "            batch_docs,            # BATCH_SIZE 수 만큼의 chunk\n",
    "            embedding=embeddings,  # 임베딩 벡터로 변환\n",
    "            index_name=PINECONE_INDEX_NAME,   # index 이름\n",
    "            namespace=PINECONE_NAMESPACE      \n",
    "        )\n",
    "\n",
    "    # 이후 배치는 생성한 벡터 스토어에 추가, # 내부적으로 임베딩 벡터로 변환\n",
    "    else:\n",
    "        vector_store.add_documents(batch_docs)    \n",
    "    \n",
    "    print(f\"배치 {i//BATCH_SIZE + 1} 완료: {len(batch_docs)}개 문서 업로드\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50abcc19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lc_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
