{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1771b629",
   "metadata": {},
   "source": [
    "# 와인 리뷰데이터 인덱싱\n",
    "- 벡터 DB : pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13b2f66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv(override=True, dotenv_path=\"../.env\")\n",
    "\n",
    "# Keys\n",
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
    "\n",
    "# Pinecone index (create it on Pinecone console beforehand)\n",
    "PINECONE_INDEX_NAME = \"wine-review2\"\n",
    "PINECONE_NAMESPACE = os.getenv(\"PINECONE_NAMESPACE\") or \"default\"\n",
    "\n",
    "# Pinecone integrated embedding model (matches your console setting)\n",
    "PINECONE_EMBEDDING_MODEL = \"llama-text-embed-v2\"\n",
    "PINECONE_EMBEDDING_DIM = 2048\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2413ed3b",
   "metadata": {},
   "source": [
    "## document loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ffe0208d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 page_content=': 0\n",
      "country: Italy\n",
      "description: Aromas include tropical fruit, broom, brimstone and dried herb. The palate isn't overly expressive, offering unripened apple, citrus and dried sage alongside brisk acidity.\n",
      "designation: Vulkà Bianco\n",
      "points: 87\n",
      "price: \n",
      "province: Sicily & Sardinia\n",
      "region_1: Etna\n",
      "region_2: \n",
      "taster_name: Kerin O’Keefe\n",
      "taster_twitter_handle: @kerinokeefe\n",
      "title: Nicosia 2013 Vulkà Bianco  (Etna)\n",
      "variety: White Blend\n",
      "winery: Nicosia' metadata={'source': './wine_reviews/winemag-data-130k-v2.csv', 'row': 0}\n",
      "1 page_content=': 1\n",
      "country: Portugal\n",
      "description: This is ripe and fruity, a wine that is smooth while still structured. Firm tannins are filled out with juicy red berry fruits and freshened with acidity. It's  already drinkable, although it will certainly be better from 2016.\n",
      "designation: Avidagos\n",
      "points: 87\n",
      "price: 15.0\n",
      "province: Douro\n",
      "region_1: \n",
      "region_2: \n",
      "taster_name: Roger Voss\n",
      "taster_twitter_handle: @vossroger\n",
      "title: Quinta dos Avidagos 2011 Avidagos Red (Douro)\n",
      "variety: Portuguese Red\n",
      "winery: Quinta dos Avidagos' metadata={'source': './wine_reviews/winemag-data-130k-v2.csv', 'row': 1}\n",
      "2 page_content=': 2\n",
      "country: US\n",
      "description: Tart and snappy, the flavors of lime flesh and rind dominate. Some green pineapple pokes through, with crisp acidity underscoring the flavors. The wine was all stainless-steel fermented.\n",
      "designation: \n",
      "points: 87\n",
      "price: 14.0\n",
      "province: Oregon\n",
      "region_1: Willamette Valley\n",
      "region_2: Willamette Valley\n",
      "taster_name: Paul Gregutt\n",
      "taster_twitter_handle: @paulgwine\n",
      "title: Rainstorm 2013 Pinot Gris (Willamette Valley)\n",
      "variety: Pinot Gris\n",
      "winery: Rainstorm' metadata={'source': './wine_reviews/winemag-data-130k-v2.csv', 'row': 2}\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import CSVLoader\n",
    "\n",
    "loader = CSVLoader('./wine_reviews/winemag-data-130k-v2.csv')\n",
    "docs = loader.load()\n",
    "for i, d in enumerate(docs[:3]):\n",
    "    print(i, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4e24b02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "129971"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5e4b5f",
   "metadata": {},
   "source": [
    "## embedding 모델 객체 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7247453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embed dim = 2048\n"
     ]
    }
   ],
   "source": [
    "# Embedding model (Pinecone Inference)\n",
    "# - Index dimension: 2048 (wine-review2)\n",
    "# - Model: llama-text-embed-v2\n",
    "# This cell enforces:\n",
    "#   1) dimension=2048 (must match the index)\n",
    "#   2) max inputs per request <= 96 (model limit)\n",
    "#   3) tokens-per-minute (TPM) throttling + 429 backoff\n",
    "\n",
    "import time\n",
    "from typing import List\n",
    "from langchain_core.embeddings import Embeddings\n",
    "from pinecone import Pinecone\n",
    "\n",
    "PINECONE_EMBEDDING_MODEL = \"llama-text-embed-v2\"\n",
    "PINECONE_EMBEDDING_DIM = 2048\n",
    "\n",
    "# Model constraints / rate limits\n",
    "MODEL_INPUTS_LIMIT = 96         # ✅ llama-text-embed-v2 inputs limit per request\n",
    "TPM_LIMIT = 250_000             # ✅ from your error message (tokens per minute)\n",
    "\n",
    "# Tuning knobs (adjust if you still see 429)\n",
    "EMBED_BATCH_LIMIT = 8           # ✅ <= 96 (8~16 recommended; lower if chunks are long)\n",
    "SAFETY = 1.35                   # ✅ safety margin for TPM throttling\n",
    "MIN_SLEEP = 1.0                 # ✅ minimum pause per call (seconds)\n",
    "MAX_RETRIES = 10                # ✅ retry count for 429\n",
    "BACKOFF_BASE = 2.0              # ✅ exponential backoff multiplier\n",
    "\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "\n",
    "def estimate_tokens(text: str) -> int:\n",
    "    \"\"\"Rough token estimator.\n",
    "    Works well enough for throttling: ~1 token per ~4 chars for English/mixed text.\n",
    "    If your chunks are mostly Korean, you can make this stricter (e.g., //3).\n",
    "    \"\"\"\n",
    "    return max(1, len(text) // 4)\n",
    "\n",
    "class PineconeInferenceEmbeddings(Embeddings):\n",
    "    def __init__(self, model: str, dim: int):\n",
    "        self.model = model\n",
    "        self.dim = dim\n",
    "\n",
    "    def _chunk(self, arr: List[str], n: int):\n",
    "        for i in range(0, len(arr), n):\n",
    "            yield arr[i:i + n]\n",
    "\n",
    "    def _sleep_for_tpm(self, inputs: List[str]):\n",
    "        total_tokens = sum(estimate_tokens(t) for t in inputs)\n",
    "        needed = (total_tokens / TPM_LIMIT) * 60.0 * SAFETY\n",
    "        time.sleep(max(MIN_SLEEP, needed))\n",
    "\n",
    "    def _embed_with_retry(self, inputs: List[str], input_type: str):\n",
    "        if len(inputs) > MODEL_INPUTS_LIMIT:\n",
    "            raise ValueError(f\"Too many inputs for one embed call: {len(inputs)} > {MODEL_INPUTS_LIMIT}\")\n",
    "\n",
    "        delay = 1.0\n",
    "        for _ in range(MAX_RETRIES):\n",
    "            try:\n",
    "                res = pc.inference.embed(\n",
    "                    model=self.model,\n",
    "                    inputs=inputs,\n",
    "                    parameters={\n",
    "                        \"input_type\": input_type,\n",
    "                        \"dimension\": self.dim,  # ✅ enforce 2048 to match the index\n",
    "                    },\n",
    "                )\n",
    "                self._sleep_for_tpm(inputs)\n",
    "                return res\n",
    "            except Exception as e:\n",
    "                msg = str(e)\n",
    "                if (\"429\" in msg) or (\"RESOURCE_EXHAUSTED\" in msg) or (\"max tokens per minute\" in msg):\n",
    "                    time.sleep(delay)\n",
    "                    delay *= BACKOFF_BASE\n",
    "                    continue\n",
    "                raise\n",
    "        raise RuntimeError(\"Embedding rate limit: retries exceeded (429)\")\n",
    "\n",
    "    def embed_documents(self, texts: List[str]) -> List[List[float]]:\n",
    "        vectors: List[List[float]] = []\n",
    "        for sub in self._chunk(texts, EMBED_BATCH_LIMIT):\n",
    "            res = self._embed_with_retry(sub, input_type=\"passage\")\n",
    "            vectors.extend([x[\"values\"] for x in res.data])\n",
    "        return vectors\n",
    "\n",
    "    def embed_query(self, text: str) -> List[float]:\n",
    "        res = self._embed_with_retry([text], input_type=\"query\")\n",
    "        return res.data[0][\"values\"]\n",
    "\n",
    "embeddings = PineconeInferenceEmbeddings(PINECONE_EMBEDDING_MODEL, PINECONE_EMBEDDING_DIM)\n",
    "\n",
    "# Quick sanity check\n",
    "print(\"embed dim =\", len(embeddings.embed_query(\"dimension check\")))  # should print 2048\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac4f4be",
   "metadata": {},
   "source": [
    "## Pinecone객체, index객체 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c27dd9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone, ServerlessSpec\n",
    "\n",
    "\n",
    "# Pinecone 클라이언트를 초기화(객체생성)\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8dcd606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index 'wine-review2' already exists.\n"
     ]
    }
   ],
   "source": [
    "# pinecone에 index list 가져오기\n",
    "existing_indexes = pc.list_indexes()\n",
    "\n",
    "# 이름만 추출\n",
    "index_names = [index['name'] for index in existing_indexes.indexes]\n",
    "# print(index_names)\n",
    "\n",
    "\n",
    "if PINECONE_INDEX_NAME not in index_names:\n",
    "    pc.create_index(\n",
    "        name=PINECONE_INDEX_NAME,\n",
    "                dimension=PINECONE_EMBEDDING_DIM,  # must match embedding dimension\n",
    "        metric=\"cosine\",  # 모델 메트릭, openapi embeding model 에서 사용하는 것 확인\n",
    "        spec=ServerlessSpec(\n",
    "            cloud=\"aws\",\n",
    "            region=\"us-east-1\"\n",
    "        )\n",
    "    )\n",
    "    print(f\"Index '{PINECONE_INDEX_NAME}' created successfully.\")\n",
    "else:\n",
    "    print(f\"Index '{PINECONE_INDEX_NAME}' already exists.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a76872",
   "metadata": {},
   "source": [
    "## Split 객체 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ebad8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split하기\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# 텍스트 분할기 설정 (예: 1000자씩 분할)\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000, \n",
    "    chunk_overlap=100,\n",
    "    # length_function=tiktoken_len,  # 토큰 기반 길이 측정    \n",
    "    length_function=len,  # 문자수   \n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    "    )\n",
    "\n",
    "# 문서를 분할\n",
    "chunks = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1198c8ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "129982"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0817897f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': './wine_reviews/winemag-data-130k-v2.csv', 'row': 2}, page_content=': 2\\ncountry: US\\ndescription: Tart and snappy, the flavors of lime flesh and rind dominate. Some green pineapple pokes through, with crisp acidity underscoring the flavors. The wine was all stainless-steel fermented.\\ndesignation: \\npoints: 87\\nprice: 14.0\\nprovince: Oregon\\nregion_1: Willamette Valley\\nregion_2: Willamette Valley\\ntaster_name: Paul Gregutt\\ntaster_twitter_handle: @paulgwine\\ntitle: Rainstorm 2013 Pinot Gris (Willamette Valley)\\nvariety: Pinot Gris\\nwinery: Rainstorm')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885a827c",
   "metadata": {},
   "source": [
    "## 배치 크기 단위로 저장하기\n",
    "- langchain_pinecone의 PineconeVectorStore으로 벡터 DB에 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c2ef46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 1 완료: 200개 문서 업로드\n",
      "배치 2 완료: 200개 문서 업로드\n",
      "배치 3 완료: 200개 문서 업로드\n",
      "배치 4 완료: 200개 문서 업로드\n",
      "배치 5 완료: 200개 문서 업로드\n",
      "배치 6 완료: 200개 문서 업로드\n",
      "배치 7 완료: 200개 문서 업로드\n",
      "배치 8 완료: 200개 문서 업로드\n",
      "배치 9 완료: 200개 문서 업로드\n",
      "배치 10 완료: 200개 문서 업로드\n",
      "배치 11 완료: 200개 문서 업로드\n",
      "배치 12 완료: 200개 문서 업로드\n",
      "배치 13 완료: 200개 문서 업로드\n",
      "배치 14 완료: 200개 문서 업로드\n",
      "배치 15 완료: 200개 문서 업로드\n",
      "배치 16 완료: 200개 문서 업로드\n",
      "배치 17 완료: 200개 문서 업로드\n",
      "배치 18 완료: 200개 문서 업로드\n",
      "배치 19 완료: 200개 문서 업로드\n",
      "배치 20 완료: 200개 문서 업로드\n",
      "배치 21 완료: 200개 문서 업로드\n",
      "배치 22 완료: 200개 문서 업로드\n",
      "배치 23 완료: 200개 문서 업로드\n",
      "배치 24 완료: 200개 문서 업로드\n",
      "배치 25 완료: 200개 문서 업로드\n",
      "배치 26 완료: 200개 문서 업로드\n",
      "배치 27 완료: 200개 문서 업로드\n",
      "배치 28 완료: 200개 문서 업로드\n",
      "배치 29 완료: 200개 문서 업로드\n",
      "배치 30 완료: 200개 문서 업로드\n",
      "배치 31 완료: 200개 문서 업로드\n",
      "배치 32 완료: 200개 문서 업로드\n",
      "배치 33 완료: 200개 문서 업로드\n",
      "배치 34 완료: 200개 문서 업로드\n",
      "배치 35 완료: 200개 문서 업로드\n",
      "배치 36 완료: 200개 문서 업로드\n",
      "배치 37 완료: 200개 문서 업로드\n",
      "배치 38 완료: 200개 문서 업로드\n",
      "배치 39 완료: 200개 문서 업로드\n",
      "배치 40 완료: 200개 문서 업로드\n",
      "배치 41 완료: 200개 문서 업로드\n",
      "배치 42 완료: 200개 문서 업로드\n",
      "배치 43 완료: 200개 문서 업로드\n",
      "배치 44 완료: 200개 문서 업로드\n",
      "배치 45 완료: 200개 문서 업로드\n",
      "배치 46 완료: 200개 문서 업로드\n",
      "배치 47 완료: 200개 문서 업로드\n",
      "배치 48 완료: 200개 문서 업로드\n",
      "배치 49 완료: 200개 문서 업로드\n",
      "배치 50 완료: 200개 문서 업로드\n",
      "배치 51 완료: 200개 문서 업로드\n",
      "배치 52 완료: 200개 문서 업로드\n",
      "배치 53 완료: 200개 문서 업로드\n",
      "배치 54 완료: 200개 문서 업로드\n",
      "배치 55 완료: 200개 문서 업로드\n",
      "배치 56 완료: 200개 문서 업로드\n",
      "배치 57 완료: 200개 문서 업로드\n",
      "배치 58 완료: 200개 문서 업로드\n",
      "배치 59 완료: 200개 문서 업로드\n",
      "배치 60 완료: 200개 문서 업로드\n",
      "배치 61 완료: 200개 문서 업로드\n",
      "배치 62 완료: 200개 문서 업로드\n",
      "배치 63 완료: 200개 문서 업로드\n",
      "배치 64 완료: 200개 문서 업로드\n",
      "배치 65 완료: 200개 문서 업로드\n",
      "배치 66 완료: 200개 문서 업로드\n",
      "배치 67 완료: 200개 문서 업로드\n",
      "배치 68 완료: 200개 문서 업로드\n",
      "배치 69 완료: 200개 문서 업로드\n",
      "배치 70 완료: 200개 문서 업로드\n",
      "배치 71 완료: 200개 문서 업로드\n",
      "배치 72 완료: 200개 문서 업로드\n",
      "배치 73 완료: 200개 문서 업로드\n",
      "배치 74 완료: 200개 문서 업로드\n",
      "배치 75 완료: 200개 문서 업로드\n",
      "배치 76 완료: 200개 문서 업로드\n",
      "배치 77 완료: 200개 문서 업로드\n",
      "배치 78 완료: 200개 문서 업로드\n",
      "배치 79 완료: 200개 문서 업로드\n",
      "배치 80 완료: 200개 문서 업로드\n",
      "배치 81 완료: 200개 문서 업로드\n",
      "배치 82 완료: 200개 문서 업로드\n",
      "배치 83 완료: 200개 문서 업로드\n",
      "배치 84 완료: 200개 문서 업로드\n",
      "배치 85 완료: 200개 문서 업로드\n",
      "배치 86 완료: 200개 문서 업로드\n",
      "배치 87 완료: 200개 문서 업로드\n",
      "배치 88 완료: 200개 문서 업로드\n",
      "배치 89 완료: 200개 문서 업로드\n",
      "배치 90 완료: 200개 문서 업로드\n",
      "배치 91 완료: 200개 문서 업로드\n",
      "배치 92 완료: 200개 문서 업로드\n",
      "배치 93 완료: 200개 문서 업로드\n",
      "배치 94 완료: 200개 문서 업로드\n",
      "배치 95 완료: 200개 문서 업로드\n",
      "배치 96 완료: 200개 문서 업로드\n",
      "배치 97 완료: 200개 문서 업로드\n",
      "배치 98 완료: 200개 문서 업로드\n",
      "배치 99 완료: 200개 문서 업로드\n",
      "배치 100 완료: 200개 문서 업로드\n",
      "배치 101 완료: 200개 문서 업로드\n",
      "배치 102 완료: 200개 문서 업로드\n",
      "배치 103 완료: 200개 문서 업로드\n",
      "배치 104 완료: 200개 문서 업로드\n",
      "배치 105 완료: 200개 문서 업로드\n"
     ]
    }
   ],
   "source": [
    "# vector sotre에 저장(2시간정도 걸림)\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "BATCH_SIZE = 200  # 업서트 배치(문서가 길면 100~200 권장)  # 한 번에 처리할 문서 수(최대 vector 수 1000개, 2MB 이내)\n",
    "\n",
    "for i in range(0, len(chunks), BATCH_SIZE):\n",
    "    batch_docs = chunks[i:i+BATCH_SIZE]\n",
    "    \n",
    "    # 첫 번째 배치로 벡터 스토어 생성\n",
    "    if i == 0:\n",
    "        vector_store = PineconeVectorStore.from_documents(\n",
    "            batch_docs,            # BATCH_SIZE 수 만큼의 chunk\n",
    "            embedding=embeddings,  # 임베딩 벡터로 변환\n",
    "            index_name=PINECONE_INDEX_NAME,   # index 이름\n",
    "            namespace=PINECONE_NAMESPACE      \n",
    "        )\n",
    "\n",
    "    # 이후 배치는 생성한 벡터 스토어에 추가, # 내부적으로 임베딩 벡터로 변환\n",
    "    else:\n",
    "        vector_store.add_documents(batch_docs)    \n",
    "    \n",
    "    print(f\"배치 {i//BATCH_SIZE + 1} 완료: {len(batch_docs)}개 문서 업로드\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50abcc19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lc_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
